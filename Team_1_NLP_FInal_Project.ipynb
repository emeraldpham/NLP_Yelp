{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7TNzYKUgTmY"
      },
      "source": [
        "# Packages Install and Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cUfVNnlBYvm",
        "outputId": "b2ef3db0-285b-4cbc-ddb5-4c07602825be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "XCYyqweeujPQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWUl48EVz703",
        "outputId": "19bd82a6-88ce-4804-fad6-255eae0244fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!pip install transformers nltk\n",
        "!pip install tensorflow\n",
        "\n",
        "# Standard library imports\n",
        "import os\n",
        "\n",
        "# Third-party imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import spearmanr, kendalltau\n",
        "from tqdm import tqdm\n",
        "\n",
        "# NLTK imports\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# TensorFlow and Keras imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, backend as K\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.layers import (Input, Layer, Embedding, Bidirectional, LSTM, Dense, Dropout,\n",
        "                                     Concatenate, GlobalAveragePooling1D, BatchNormalization,\n",
        "                                     LayerNormalization)\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.mixed_precision import global_policy\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Sklearn imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import (mean_absolute_error, mean_squared_error, accuracy_score,\n",
        "                             precision_score, recall_score, f1_score)\n",
        "\n",
        "# Transformers imports\n",
        "from transformers import pipeline, BertTokenizer, TFAutoModelForSequenceClassification, AutoTokenizer, TFBertForSequenceClassification\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up GPU device\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    print('GPU available')\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "metadata": {
        "id": "RvnmE18W3lhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3ec2dd-31f4-4685-e349-8338903d9b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "TSQ8fI2tuC4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation Code"
      ],
      "metadata": {
        "id": "lx4xHEYguFPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_correlation_matrix(df, *columns):\n",
        "    if not all(column in df for column in columns):\n",
        "        raise ValueError(\"One or more specified columns do not exist in the DataFrame.\")\n",
        "    data_temp = df[list(columns)]\n",
        "    correlation_matrix = data_temp.corr()\n",
        "\n",
        "    # Plot correlation matrix as a heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "    plt.title('Correlation Matrix')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lZ2IlK7guHN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Code"
      ],
      "metadata": {
        "id": "OHWYj6XJylJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_discrete(continuous_values):\n",
        "  discrete_scores = [1 if x <= 0.2 else\n",
        "                    2 if x <= 0.4 else\n",
        "                    3 if x <= 0.6 else\n",
        "                    4 if x <= 0.8 else\n",
        "                    5 for x in continuous_values]\n",
        "  return discrete_scores"
      ],
      "metadata": {
        "id": "q8brgxzExMj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(column_one, column_two):\n",
        "  # Multiclass accuracy\n",
        "  accuracy = accuracy_score(column_one, column_two)\n",
        "  print(f\"Multiclass Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "  # Weighted Accuracy: Absolute difference scaled inversely by the max error (4 in this case, e.g., 1 vs. 5)\n",
        "  weighted_accuracies = 1 - (np.abs(column_one - column_two) / 4)\n",
        "  mean_accuracy = np.mean(weighted_accuracies)\n",
        "  print(f\"Weighted Mutliclass Accuracy: {mean_accuracy:.3f}\")\n",
        "\n",
        "  # Spearman's rank correlation\n",
        "  spearman_corr, _ = spearmanr(column_one, column_two)\n",
        "  print(f\"Spearman's Rank Correlation: {spearman_corr:.3f}\")\n",
        "\n",
        "  # Kendall's tau\n",
        "  kendall_corr, _ = kendalltau(column_one, column_two)\n",
        "  print(f\"Kendall's tau: {kendall_corr:.3f}\")"
      ],
      "metadata": {
        "id": "c-meWZur8i_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_val, y_val_sentiment, y_val_sarcasm, X_test, y_test_sentiment, y_test_sarcasm):\n",
        "    # Predictions for the validation set\n",
        "    val_predictions = model.predict(X_val)\n",
        "    val_sentiment_predictions = val_predictions[0]\n",
        "    val_sarcasm_predictions = val_predictions[1]\n",
        "\n",
        "    # Predictions for the test set\n",
        "    test_predictions = model.predict(X_test)\n",
        "    test_sentiment_predictions = test_predictions[0]\n",
        "    test_sarcasm_predictions = test_predictions[1]\n",
        "\n",
        "    val_sarcasm_labels = (val_sarcasm_predictions > 0.5).astype(int)\n",
        "    test_sarcasm_labels = (test_sarcasm_predictions > 0.5).astype(int)\n",
        "\n",
        "    # Metrics for sentiment analysis\n",
        "    val_mse = mean_squared_error(y_val_sentiment, val_sentiment_predictions)\n",
        "    val_mae = mean_absolute_error(y_val_sentiment, val_sentiment_predictions)\n",
        "    test_mse = mean_squared_error(y_test_sentiment, test_sentiment_predictions)\n",
        "    test_mae = mean_absolute_error(y_test_sentiment, test_sentiment_predictions)\n",
        "\n",
        "    # Metrics for sarcasm detection\n",
        "    val_accuracy = accuracy_score(y_val_sarcasm, val_sarcasm_labels)\n",
        "    val_precision = precision_score(y_val_sarcasm, val_sarcasm_labels)\n",
        "    val_recall = recall_score(y_val_sarcasm, val_sarcasm_labels)\n",
        "    val_f1 = f1_score(y_val_sarcasm, val_sarcasm_labels)\n",
        "    test_accuracy = accuracy_score(y_test_sarcasm, test_sarcasm_labels)\n",
        "    test_precision = precision_score(y_test_sarcasm, test_sarcasm_labels)\n",
        "    test_recall = recall_score(y_test_sarcasm, test_sarcasm_labels)\n",
        "    test_f1 = f1_score(y_test_sarcasm, test_sarcasm_labels)\n",
        "\n",
        "    print(\"Validation - Sentiment Analysis: MSE =\", val_mse, \", MAE =\", val_mae)\n",
        "    print(\"Validation - Sarcasm Detection: Accuracy =\", val_accuracy, \", Precision =\", val_precision, \", Recall =\", val_recall, \", F1 Score =\", val_f1)\n",
        "    print(\"Test - Sentiment Analysis: MSE =\", test_mse, \", MAE =\", test_mae)\n",
        "    print(\"Test - Sarcasm Detection: Accuracy =\", test_accuracy, \", Precision =\", test_precision, \", Recall =\", test_recall, \", F1 Score =\", test_f1)\n",
        "\n",
        "    return {\n",
        "        'val': {\n",
        "            'sentiment': {'mse': val_mse, 'mae': val_mae},\n",
        "            'sarcasm': {'accuracy': val_accuracy, 'precision': val_precision, 'recall': val_recall, 'f1': val_f1}\n",
        "        },\n",
        "        'test': {\n",
        "            'sentiment': {'mse': test_mse, 'mae': test_mae},\n",
        "            'sarcasm': {'accuracy': test_accuracy, 'precision': test_precision, 'recall': test_recall, 'f1': test_f1}\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "dEJebE51ynB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Head Attention"
      ],
      "metadata": {
        "id": "rXnnz50ly2ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(Layer):\n",
        "    def __init__(self, num_heads, model_dim, **kwargs):\n",
        "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.model_dim = model_dim\n",
        "        assert model_dim % num_heads == 0, \"model_dim must be divisible by num_heads\"\n",
        "        self.depth = model_dim // num_heads\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.Wq = self.add_weight(shape=(input_shape[-1], self.model_dim),\n",
        "                                  initializer='glorot_uniform', trainable=True, name='query_weight')\n",
        "        self.Wk = self.add_weight(shape=(input_shape[-1], self.model_dim),\n",
        "                                  initializer='glorot_uniform', trainable=True, name='key_weight')\n",
        "        self.Wv = self.add_weight(shape=(input_shape[-1], self.model_dim),\n",
        "                                  initializer='glorot_uniform', trainable=True, name='value_weight')\n",
        "        self.dense = Dense(self.model_dim)\n",
        "        super(MultiHeadAttention, self).build(input_shape)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = K.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return K.permute_dimensions(x, pattern=(0, 2, 1, 3))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        query = K.dot(inputs, self.Wq)\n",
        "        key = K.dot(inputs, self.Wk)\n",
        "        value = K.dot(inputs, self.Wv)\n",
        "\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        attention, weights = self.scaled_dot_product_attention(query, key, value)\n",
        "        attention = K.permute_dimensions(attention, pattern=(0, 2, 1, 3))\n",
        "        concat_attention = K.reshape(attention, (batch_size, -1, self.model_dim))\n",
        "\n",
        "        output = self.dense(concat_attention)\n",
        "        return output\n",
        "\n",
        "    def scaled_dot_product_attention(self, query, key, value):\n",
        "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "        dk = tf.cast(tf.shape(key)[-1], dtype=global_policy().compute_dtype)\n",
        "\n",
        "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "        output = tf.matmul(attention_weights, value)\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "id": "oOrpgqYPyzU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Yelp Dataset"
      ],
      "metadata": {
        "id": "HeWBVQtWudty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading"
      ],
      "metadata": {
        "id": "WCjb6iobwhYl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2a5_kQNgqoc",
        "outputId": "a94ee482-8eb3-4ba1-c06f-59cb835c8616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id   ProductId          UserId                      ProfileName  \\\n",
            "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
            "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
            "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
            "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
            "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
            "\n",
            "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
            "0                     1                       1      5  1303862400   \n",
            "1                     0                       0      1  1346976000   \n",
            "2                     1                       1      4  1219017600   \n",
            "3                     3                       3      2  1307923200   \n",
            "4                     0                       0      5  1350777600   \n",
            "\n",
            "                 Summary                                               Text  \n",
            "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
            "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
            "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
            "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
            "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
          ]
        }
      ],
      "source": [
        "file_path = '/content/drive/MyDrive/Yelp Dataset/Reviews.csv'\n",
        "# file_path = '/content/drive/MyDrive/WPI/DS595_NLP/Final Project/Reviews.csv'\n",
        "yelp_df = pd.read_csv(file_path)\n",
        "print(yelp_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Balancing (Undersampling)"
      ],
      "metadata": {
        "id": "5bvmKq4kwcrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyzing Score Distribution\n",
        "score_distribution = yelp_df['Score'].value_counts()\n",
        "print(\"Original distribution:\\n\", score_distribution)\n",
        "min_class_size = yelp_df['Score'].value_counts().min()\n",
        "\n",
        "# Resampling dataset to balance\n",
        "df_balanced = pd.DataFrame()\n",
        "\n",
        "for score in yelp_df['Score'].unique():\n",
        "    df_score = yelp_df[yelp_df['Score'] == score]\n",
        "    df_score_downsampled = resample(df_score,\n",
        "                                    replace=False,\n",
        "                                    n_samples=min_class_size,\n",
        "                                    random_state=123)\n",
        "    df_balanced = pd.concat([df_balanced, df_score_downsampled])\n",
        "\n",
        "# New Distribution\n",
        "new_score_distribution = df_balanced['Score'].value_counts()\n",
        "print(\"New distribution:\\n\", new_score_distribution)\n",
        "yelp_df = df_balanced"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Upg8PZbmuvvz",
        "outputId": "ed0ade5c-1cfb-449e-fe4b-496dc2cea14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original distribution:\n",
            " Score\n",
            "5    363122\n",
            "4     80655\n",
            "1     52268\n",
            "3     42640\n",
            "2     29769\n",
            "Name: count, dtype: int64\n",
            "New distribution:\n",
            " Score\n",
            "5    29769\n",
            "1    29769\n",
            "4    29769\n",
            "2    29769\n",
            "3    29769\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train/Test Split"
      ],
      "metadata": {
        "id": "e2YpLZvFwXha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yelp_df_train_val, yelp_df_test = train_test_split(\n",
        "    yelp_df,\n",
        "    test_size=0.2,  # 20% for testing\n",
        "    random_state=42)\n",
        "\n",
        "yelp_df_train, yelp_df_val = train_test_split(\n",
        "    yelp_df_train_val,\n",
        "    test_size=0.25,  # 25% of 80% (20% of the total data)\n",
        "    random_state=42)"
      ],
      "metadata": {
        "id": "A9ncST7t1LRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary']\n",
        "yelp_df_test = yelp_df_test.drop(columns=columns_to_drop)\n",
        "\n",
        "print(yelp_df_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuhMCkWS5jLx",
        "outputId": "ce49f7a7-4958-4835-ec2b-87345df5bb87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Score                                               Text\n",
            "289438      1  This was an X-mas gift for my dog and he loved...\n",
            "333254      5  Surprised me.....This one is really good.  Fla...\n",
            "333853      1  Bought the nacho chips regularly for my kids b...\n",
            "414716      4  Well, I wasn't bright when I ordered this coff...\n",
            "359800      1  These chips (all flavors of the variety pack) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BsvsZiY1Y9L"
      },
      "source": [
        "# Sentiment analysis using NLTK package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCgdM8pv1YYD"
      },
      "outputs": [],
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_compound_sentiment(text):\n",
        "    return sia.polarity_scores(text)['compound']\n",
        "\n",
        "yelp_df_test['NLTK_Compound_Score'] = yelp_df_test['Text'].apply(get_compound_sentiment)\n",
        "\n",
        "def normalize_score(compound_score):\n",
        "    # Transform from [-1, 1] to [1, 5]\n",
        "    return 1 + (compound_score + 1) * 2\n",
        "\n",
        "yelp_df_test['NLTK_Normalized_Score'] = yelp_df_test['NLTK_Compound_Score'].apply(normalize_score).round().astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6F73N_8f_pu3"
      },
      "outputs": [],
      "source": [
        "calculate_metrics(yelp_df_test['NLTK_Normalized_Score'],yelp_df_test['Score'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_correlation_matrix(yelp_df_test, \"Score\", \"NLTK_Normalized_Score\")"
      ],
      "metadata": {
        "id": "3ag_uEc8r0dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis using a Pretrained BERT Model"
      ],
      "metadata": {
        "id": "6vygUtduu2fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "texts = yelp_df_test['Text'].tolist()\n",
        "batch_size = 128\n",
        "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors=\"tf\", max_length=512)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded_input).batch(batch_size)\n",
        "\n",
        "scores = []\n",
        "for batch in dataset:\n",
        "    predictions = model(batch)\n",
        "    batch_scores = tf.argmax(predictions.logits, axis=1) + 1\n",
        "    scores.extend(batch_scores.numpy())\n",
        "\n",
        "yelp_df_test['BERT_Score'] = scores"
      ],
      "metadata": {
        "id": "kOj1n1bFOBsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_metrics(yelp_df_test['Score'], yelp_df_test['BERT_Score'])"
      ],
      "metadata": {
        "id": "Go-FTE4VQTVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_correlation_matrix(yelp_df_test, \"Score\", \"BERT_Score\")"
      ],
      "metadata": {
        "id": "75qs_YUywCFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis using a Custom Sarcasm Detector + Sentiment Model Combination"
      ],
      "metadata": {
        "id": "vTeYyfvAu-1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "max_length = 100\n",
        "embedding_dim = 200\n",
        "padding_type = 'post'\n",
        "trunc_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=oov_tok)"
      ],
      "metadata": {
        "id": "AkOcRZm2qBKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC3l01Xpg-j2"
      },
      "source": [
        "### Sarcasm Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6qUJkiJz59L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998d8ce4-067e-499f-eec0-8f6fa085153f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   is_sarcastic                                           headline  \\\n",
            "0             1  thirtysomething scientists unveil doomsday clo...   \n",
            "1             0  dem rep. totally nails why congress is falling...   \n",
            "2             0  eat your veggies: 9 deliciously different recipes   \n",
            "3             1  inclement weather prevents liar from getting t...   \n",
            "4             1  mother comes pretty close to using word 'strea...   \n",
            "\n",
            "                                        article_link  \n",
            "0  https://www.theonion.com/thirtysomething-scien...  \n",
            "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
            "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
            "3  https://local.theonion.com/inclement-weather-p...  \n",
            "4  https://www.theonion.com/mother-comes-pretty-c...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 200)          2000000   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               135680    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 24)                3096      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2138801 (8.16 MB)\n",
            "Trainable params: 2138801 (8.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "179/179 [==============================] - 54s 272ms/step - loss: 0.4054 - accuracy: 0.8042 - val_loss: 0.3133 - val_accuracy: 0.8622\n",
            "Epoch 2/10\n",
            "179/179 [==============================] - 39s 217ms/step - loss: 0.2037 - accuracy: 0.9197 - val_loss: 0.3226 - val_accuracy: 0.8615\n",
            "Epoch 3/10\n",
            "179/179 [==============================] - 37s 207ms/step - loss: 0.1274 - accuracy: 0.9523 - val_loss: 0.3699 - val_accuracy: 0.8571\n",
            "Epoch 4/10\n",
            "179/179 [==============================] - 36s 203ms/step - loss: 0.0745 - accuracy: 0.9744 - val_loss: 0.4683 - val_accuracy: 0.8531\n",
            "Epoch 5/10\n",
            "179/179 [==============================] - 37s 210ms/step - loss: 0.0487 - accuracy: 0.9841 - val_loss: 0.5982 - val_accuracy: 0.8489\n",
            "Epoch 6/10\n",
            "179/179 [==============================] - 36s 204ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.6978 - val_accuracy: 0.8442\n",
            "Epoch 7/10\n",
            "179/179 [==============================] - 37s 205ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.8030 - val_accuracy: 0.8394\n",
            "Epoch 8/10\n",
            "179/179 [==============================] - 36s 204ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.9065 - val_accuracy: 0.8367\n",
            "Epoch 9/10\n",
            "179/179 [==============================] - 37s 204ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.8603 - val_accuracy: 0.8440\n",
            "Epoch 10/10\n",
            "179/179 [==============================] - 36s 202ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.8573 - val_accuracy: 0.8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8572922348976135\n",
            "Validation Accuracy: 0.846960186958313\n",
            "179/179 [==============================] - 5s 27ms/step\n",
            "Precision: 0.8458379992534528\n",
            "Recall: 0.8303407841700257\n",
            "F1 Score: 0.8380177514792899\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/Yelp Dataset/Sarcasm_Headlines_Dataset_v2.json', lines=True)\n",
        "# df = pd.read_json('/content/drive/MyDrive/WPI/DS595_NLP/Final Project/Sarcasm_Headlines_Dataset_v2.json', lines=True)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "tokenizer.fit_on_texts(df['headline'])\n",
        "\n",
        "# Convert text to sequences and pad\n",
        "sequences = tokenizer.texts_to_sequences(df['headline'])\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "labels = df['is_sarcastic'].values\n",
        "\n",
        "model_sarcasm = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(24, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_sarcasm.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "model_sarcasm.summary()\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(padded, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "history = model_sarcasm.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=128)\n",
        "# model_sarcasm = load_model('/content/drive/MyDrive/WPI/DS595_NLP/Final Project/model_sarcasm.h5')\n",
        "\n",
        "model_path = '/content/drive/MyDrive/Yelp Dataset/model_sarcasm.h5'\n",
        "# # model_sarcasm = load_model('/content/drive/MyDrive/Yelp Dataset/Yelp Pred Train Test Split/model_sarcasm.h5')\n",
        "model_sarcasm.save(model_path)\n",
        "\n",
        "weights_path = '/content/drive/MyDrive/Yelp Dataset/model_sarcasm_weights.h5'\n",
        "# # weights_path = '/content/drive/MyDrive/WPI/DS595_NLP/Final Project/model_sarcasm_weights.h5'\n",
        "model_sarcasm.save_weights(weights_path)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "loss, accuracy = model_sarcasm.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "print(f'Validation Loss: {loss}')\n",
        "print(f'Validation Accuracy: {accuracy}')\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model_sarcasm.predict(X_val)\n",
        "predictions_binary = (predictions > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calculate Precision, Recall, and F1 Score\n",
        "precision = precision_score(y_val, predictions_binary)\n",
        "recall = recall_score(y_val, predictions_binary)\n",
        "f1 = f1_score(y_val, predictions_binary)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2KjGHYykUXw"
      },
      "source": [
        "### Sentiment Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJn5AcWmim50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583e8e8e-d5b2-46be-cfa6-ef7d34c15dbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of phrase_df: (239232, 2)\n",
            "Size of label_df: (239232, 2)\n",
            "        Phrase      ID  phrase ids  sentiment values\n",
            "0            !       0           0           0.50000\n",
            "1          ! '   22935       22935           0.52778\n",
            "2         ! ''   18235       18235           0.50000\n",
            "3       ! Alas  179257      179257           0.44444\n",
            "4  ! Brilliant   22936       22936           0.86111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " bidirectional_12 (Bidirect  (None, 100, 128)          84480     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirect  (None, 64)                41216     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1129921 (4.31 MB)\n",
            "Trainable params: 1129921 (4.31 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "phrase_file_path = '/content/drive/MyDrive/Yelp Dataset/stanfordSentimentTreebank/dictionary.txt'\n",
        "# phrase_file_path = '/content/drive/MyDrive/WPI/DS595_NLP/Final Project/dictionary.txt'\n",
        "\n",
        "phrase_df = pd.read_csv(phrase_file_path, sep='|', header=None, names=['Phrase', 'ID'])\n",
        "\n",
        "labels_file_path = '/content/drive/MyDrive/Yelp Dataset/stanfordSentimentTreebank/sentiment_labels.txt'\n",
        "# labels_file_path = '/content/drive/MyDrive/WPI/DS595_NLP/Final Project/sentiment_labels.txt'\n",
        "\n",
        "label_df = pd.read_csv(labels_file_path, sep='|', header=0)\n",
        "\n",
        "print(f\"Size of phrase_df: {phrase_df.shape}\")\n",
        "print(f\"Size of label_df: {label_df.shape}\")\n",
        "\n",
        "df_sentiment = pd.merge(phrase_df, label_df, left_on='ID', right_on='phrase ids')\n",
        "\n",
        "print(df_sentiment.head())\n",
        "\n",
        "df_sentiment.dropna(subset=['Phrase'], inplace=True)\n",
        "tokenizer.fit_on_texts(df_sentiment['Phrase'])\n",
        "sequences = tokenizer.texts_to_sequences(df_sentiment['Phrase'])\n",
        "padded = pad_sequences(sequences, maxlen=100)\n",
        "\n",
        "X_train_sentiment, X_val_sentiment, y_train_sentiment, y_val_sentiment = train_test_split(padded, df_sentiment['sentiment values'], test_size=0.2, random_state=42)\n",
        "\n",
        "model_sentiment = Sequential([\n",
        "    Embedding(10000, 100, input_length=100),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(32)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model_sentiment.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "\n",
        "model_sentiment.summary()\n",
        "\n",
        "history = model_sentiment.fit(X_train_sentiment, y_train_sentiment, epochs=10, validation_data=(X_val_sentiment, y_val_sentiment), batch_size=1024)\n",
        "# model_sentiment = load_model('/content/drive/MyDrive/WPI/DS595_NLP/Final Project/model_sentiment.h5')\n",
        "\n",
        "weights_path = '/content/drive/MyDrive/Yelp Dataset/model_sentiment_weights.h5'\n",
        "# weights_path = '/content/drive/MyDrive/WPI/DS595_NLP/Final Project/model_sentiment_weights.h5'\n",
        "model_sentiment.save_weights(weights_path)\n",
        "\n",
        "model_path = '/content/drive/MyDrive/Yelp Dataset/model_sentiment.h5'\n",
        "# model_path = '/content/drive/MyDrive/WPI/DS595_NLP/Final Project/model_sentiment.h5'\n",
        "model_sentiment.save(model_path)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "loss, accuracy = model_sentiment.evaluate(X_val_sentiment, y_val_sentiment, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcMuRKObLvkK"
      },
      "source": [
        "### Using Sarcasm Model to label Sentiment Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43j1et1wL2K2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d8632e3-4044-4b89-9a7f-9e7012b1a776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7476/7476 [==============================] - 196s 26ms/step\n",
            "        Phrase      ID  phrase ids  sentiment values  Sarcasm Label\n",
            "0            !       0           0           0.50000              0\n",
            "1          ! '   22935       22935           0.52778              0\n",
            "2         ! ''   18235       18235           0.50000              0\n",
            "3       ! Alas  179257      179257           0.44444              0\n",
            "4  ! Brilliant   22936       22936           0.86111              1\n"
          ]
        }
      ],
      "source": [
        "sentiment_sequences = tokenizer.texts_to_sequences(df_sentiment['Phrase'])\n",
        "sentiment_padded = pad_sequences(sentiment_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "sarcasm_predictions = model_sarcasm.predict(sentiment_padded)\n",
        "sarcasm_labels_binary = (sarcasm_predictions > 0.5).astype(int)\n",
        "\n",
        "df_sentiment['Sarcasm Label'] = sarcasm_labels_binary\n",
        "\n",
        "print(df_sentiment.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(df_sentiment['Phrase'])\n",
        "sequences = tokenizer.texts_to_sequences(df_sentiment['Phrase'])\n",
        "X_padded = pad_sequences(sequences, maxlen=100)\n",
        "\n",
        "X_train_sentiment, X_temp_sentiment, y_train_sentiment, y_temp_sentiment, y_train_sarcasm, y_temp_sarcasm = train_test_split(\n",
        "    X_padded,\n",
        "    df_sentiment['sentiment values'],\n",
        "    df_sentiment['Sarcasm Label'],\n",
        "    test_size=0.4,\n",
        "    random_state=42)\n",
        "\n",
        "X_val_sentiment, X_test_sentiment, y_val_sentiment, y_test_sentiment, y_val_sarcasm, y_test_sarcasm = train_test_split(\n",
        "    X_temp_sentiment,\n",
        "    y_temp_sentiment,\n",
        "    y_temp_sarcasm,\n",
        "    test_size=0.5,\n",
        "    random_state=42)\n",
        "\n",
        "# Prepare labels for multi-output\n",
        "sentiment_train_labels = {'sentiment_output': y_train_sentiment, 'sarcasm_output': y_train_sarcasm}\n",
        "sentiment_val_labels = {'sentiment_output': y_val_sentiment, 'sarcasm_output': y_val_sarcasm}\n",
        "sentiment_test_labels = {'sentiment_output': y_test_sentiment, 'sarcasm_output': y_test_sarcasm}"
      ],
      "metadata": {
        "id": "vQAHeRupZOsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0U8QzQhwMeD"
      },
      "source": [
        "### Applying the Custom Sentiment Model to the Yelp Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1RMr1kWwMKS"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts(yelp_df_train['Text'])\n",
        "\n",
        "# Tokenize and pad Yelp review sequences\n",
        "yelp_train_sequences = tokenizer.texts_to_sequences(yelp_df_train['Text'])\n",
        "X_train_yelp = pad_sequences(yelp_train_sequences, maxlen=100)\n",
        "yelp_val_sequences = tokenizer.texts_to_sequences(yelp_df_val['Text'])\n",
        "X_val_yelp = pad_sequences(yelp_val_sequences, maxlen=100)\n",
        "yelp_test_sequences = tokenizer.texts_to_sequences(yelp_df_test['Text'])\n",
        "X_test_yelp = pad_sequences(yelp_test_sequences, maxlen=100)\n",
        "\n",
        "min_score = 1\n",
        "max_score = 5\n",
        "\n",
        "# Normalize the scores to be between 0 and 1\n",
        "y_train_yelp_normalized = (yelp_df_train['Score'] - min_score) / (max_score - min_score)\n",
        "y_val_yelp_normalized = (yelp_df_val['Score'] - min_score) / (max_score - min_score)\n",
        "y_test_yelp_normalized = (yelp_df_test['Score'] - min_score) / (max_score - min_score)\n",
        "\n",
        "# Convert scores to a format suitable for regression\n",
        "y_train_yelp = y_train_yelp_normalized.values.astype(float)\n",
        "y_val_yelp = y_val_yelp_normalized.values.astype(float)\n",
        "y_test_yelp = y_test_yelp_normalized.values.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_sentiment = load_model('/content/drive/MyDrive/Yelp Dataset/model_sentiment.h5')\n",
        "history_yelp = model_sentiment.fit(X_train_yelp, y_train_yelp, epochs=10, validation_data=(X_val_yelp, y_val_yelp), batch_size=1024)\n",
        "\n",
        "loss_yelp, mae_yelp = model_sentiment.evaluate(X_val_yelp, y_val_yelp, verbose=0)\n",
        "print(f\"Loss on Yelp data: {loss_yelp}\")\n",
        "print(f\"Mean Absolute Error on Yelp data: {mae_yelp}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYqVRVmIvP-K",
        "outputId": "92d892de-cd1e-4040-cfc8-733bc59adcf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "88/88 [==============================] - 50s 511ms/step - loss: 0.1103 - mean_absolute_error: 0.2707 - val_loss: 0.0624 - val_mean_absolute_error: 0.2003\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 42s 481ms/step - loss: 0.0546 - mean_absolute_error: 0.1851 - val_loss: 0.0556 - val_mean_absolute_error: 0.1860\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 41s 464ms/step - loss: 0.0475 - mean_absolute_error: 0.1711 - val_loss: 0.0547 - val_mean_absolute_error: 0.1795\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 40s 453ms/step - loss: 0.0423 - mean_absolute_error: 0.1584 - val_loss: 0.0509 - val_mean_absolute_error: 0.1733\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 39s 446ms/step - loss: 0.0377 - mean_absolute_error: 0.1473 - val_loss: 0.0520 - val_mean_absolute_error: 0.1726\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 39s 443ms/step - loss: 0.0339 - mean_absolute_error: 0.1391 - val_loss: 0.0529 - val_mean_absolute_error: 0.1668\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 38s 433ms/step - loss: 0.0304 - mean_absolute_error: 0.1312 - val_loss: 0.0527 - val_mean_absolute_error: 0.1663\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 38s 426ms/step - loss: 0.0277 - mean_absolute_error: 0.1244 - val_loss: 0.0527 - val_mean_absolute_error: 0.1684\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 38s 430ms/step - loss: 0.0249 - mean_absolute_error: 0.1175 - val_loss: 0.0556 - val_mean_absolute_error: 0.1664\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 38s 430ms/step - loss: 0.0226 - mean_absolute_error: 0.1117 - val_loss: 0.0557 - val_mean_absolute_error: 0.1657\n",
            "Loss on Yelp data: 0.05565645173192024\n",
            "Mean Absolute Error on Yelp data: 0.1658799797296524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_sentiment.predict(X_val_yelp[10:15]))\n",
        "print(y_val_yelp[10:15])"
      ],
      "metadata": {
        "id": "ChG7flXjVm3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb3e4e0-89f8-4ff4-c8d3-6e6ab78adf69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 514ms/step\n",
            "[[0.15503009]\n",
            " [0.04428293]\n",
            " [0.38575307]\n",
            " [0.44541404]\n",
            " [0.38169912]]\n",
            "[0.5  0.   0.5  0.25 1.  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_continuous_test = model_sentiment.predict(X_test_yelp)\n",
        "predicted_rounded_test = convert_to_discrete(predicted_continuous_test)\n",
        "yelp_df_test[\"Custom Sentiment Model Score, no Sarcasm\"] = predicted_rounded_test\n",
        "\n",
        "predicted_continuous_val = model_sentiment.predict(X_val_yelp)\n",
        "predicted_rounded_val = convert_to_discrete(predicted_continuous_val)\n",
        "yelp_df_val[\"Custom Sentiment Model Score, no Sarcasm\"] = predicted_rounded_val\n",
        "\n",
        "predicted_continuous_train = model_sentiment.predict(X_train_yelp)\n",
        "predicted_rounded_train = convert_to_discrete(predicted_continuous_train)\n",
        "yelp_df_train[\"Custom Sentiment Model Score, no Sarcasm\"] = predicted_rounded_train\n",
        "\n",
        "calculate_metrics(yelp_df_test['Score'], yelp_df_test['Custom Sentiment Model Score, no Sarcasm'])"
      ],
      "metadata": {
        "id": "24T0LxUmrb1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7bfb98-4dd6-406c-f521-1239d93994d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "931/931 [==============================] - 48s 51ms/step\n",
            "931/931 [==============================] - 50s 53ms/step\n",
            "2791/2791 [==============================] - 143s 51ms/step\n",
            "Multiclass Accuracy: 0.521\n",
            "Weighted Mutliclass Accuracy: 0.837\n",
            "Spearman's Rank Correlation: 0.748\n",
            "Kendall's tau: 0.657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sarcasm_predictions = model_sarcasm.predict(X_train_yelp)\n",
        "val_sarcasm_predictions = model_sarcasm.predict(X_val_yelp)\n",
        "test_sarcasm_predictions = model_sarcasm.predict(X_test_yelp)\n",
        "\n",
        "train_sarcasm_labels_binary = (train_sarcasm_predictions > 0.5).astype(int)\n",
        "val_sarcasm_labels_binary = (val_sarcasm_predictions > 0.5).astype(int)\n",
        "test_sarcasm_labels_binary = (test_sarcasm_predictions > 0.5).astype(int)\n",
        "\n",
        "yelp_df_train['Sarcasm Label'] = train_sarcasm_labels_binary\n",
        "yelp_df_val['Sarcasm Label'] = val_sarcasm_labels_binary\n",
        "yelp_df_test['Sarcasm Label'] = test_sarcasm_labels_binary\n",
        "\n",
        "yelp_train_labels = {'sentiment_output': y_train_yelp, 'sarcasm_output': train_sarcasm_labels_binary}\n",
        "yelp_val_labels = {'sentiment_output': y_val_yelp, 'sarcasm_output': val_sarcasm_labels_binary}\n",
        "yelp_test_labels = {'sentiment_output': y_test_yelp, 'sarcasm_output': test_sarcasm_labels_binary}"
      ],
      "metadata": {
        "id": "53zSBilzY1ux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf70f3f-3dd9-4411-b142-8fffcf12a167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2791/2791 [==============================] - 73s 26ms/step\n",
            "931/931 [==============================] - 24s 26ms/step\n",
            "931/931 [==============================] - 25s 27ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_weights = model_sentiment.save_weights('/content/drive/MyDrive/Yelp Dataset/model_sentiment_weights.h5')\n",
        "sarcasm_weights = model_sarcasm.save_weights('/content/drive/MyDrive/Yelp Dataset/model_sarcasm_weights.h5')"
      ],
      "metadata": {
        "id": "QE526lXaCmeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TInG5AExqYqr"
      },
      "source": [
        "### Custom Combined Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_weights = '/content/drive/MyDrive/Yelp Dataset/model_sentiment_weights.h5'\n",
        "sarcasm_weights = '/content/drive/MyDrive/Yelp Dataset/model_sarcasm_weights.h5'\n",
        "# sentiment_weights = '/content/drive/MyDrive/WPI/DS595_NLP/Final Project/model_sentiment_yelp_weights.h5'\n",
        "# sarcasm_weights = '/content/drive/MyDrive/WPI/DS595_NLP/Final Project/model_sarcasm_weights.h5'\n",
        "\n",
        "input_shape = 100  # max_length for sentiment and sarcasm models\n",
        "\n",
        "# Rebuild the sentiment model architecture\n",
        "sentiment_base = tf.keras.Sequential([\n",
        "    Embedding(10000, 100, input_length=input_shape),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(32)),\n",
        "    Dense(64, activation='relu')\n",
        "])\n",
        "\n",
        "sentiment_base.load_weights(sentiment_weights, by_name=True)\n",
        "\n",
        "# for layer in sentiment_base.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# Rebuild the sarcasm model architecture\n",
        "sarcasm_base = tf.keras.Sequential([\n",
        "    Embedding(10000, 100, input_length=input_shape),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(24, activation='relu')\n",
        "])\n",
        "\n",
        "sarcasm_base.load_weights(sarcasm_weights, by_name=True)\n",
        "\n",
        "# for layer in sarcasm_base.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "input_layer = Input(shape=(input_shape,))\n",
        "\n",
        "sentiment_features = sentiment_base(input_layer)\n",
        "sarcasm_features = sarcasm_base(input_layer)\n",
        "\n",
        "combined_features = Concatenate()([sentiment_features, sarcasm_features])\n",
        "\n",
        "x = Dense(64, activation='relu')(combined_features)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "sentiment_output = Dense(1, activation='sigmoid', name='sentiment_output')(x)\n",
        "sarcasm_output = Dense(1, activation='sigmoid', name='sarcasm_output')(x)\n",
        "\n",
        "combined_model = Model(inputs=input_layer, outputs=[sentiment_output, sarcasm_output])\n",
        "combined_model.compile(optimizer=Adam(0.0001),\n",
        "                       loss={'sentiment_output': 'categorical_crossentropy', 'sarcasm_output': 'binary_crossentropy'},\n",
        "                       metrics={'sentiment_output': ['mean_absolute_error'], 'sarcasm_output': ['accuracy']})\n",
        "\n",
        "combined_model.summary()"
      ],
      "metadata": {
        "id": "JqoF-nZMtzyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421d2228-9497-4a81-ef55-dc12b71c6622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " sequential_10 (Sequential)  (None, 64)                   1129856   ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " sequential_11 (Sequential)  (None, 24)                   1087576   ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 88)                   0         ['sequential_10[0][0]',       \n",
            " )                                                                   'sequential_11[0][0]']       \n",
            "                                                                                                  \n",
            " dense_20 (Dense)            (None, 64)                   5696      ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 64)                   0         ['dense_20[0][0]']            \n",
            "                                                                                                  \n",
            " sentiment_output (Dense)    (None, 1)                    65        ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " sarcasm_output (Dense)      (None, 1)                    65        ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2223258 (8.48 MB)\n",
            "Trainable params: 2223258 (8.48 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001, verbose=1)\n",
        "\n",
        "combined_model.fit(\n",
        "    X_train_sentiment, sentiment_train_labels,\n",
        "    validation_data=(X_val_sentiment, sentiment_val_labels),\n",
        "    epochs=15,\n",
        "    batch_size=2048,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "id": "pIwyBtQdERfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_df_combined_predictions = combined_model.predict(X_test_sentiment)"
      ],
      "metadata": {
        "id": "PSHTs5MKnx7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245ab5a4-8a3f-41fa-eecb-7934bea2f5a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1496/1496 [==============================] - 113s 75ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_df_combined_predictions\n",
        "sentiment_predictions = pd.Series(sentiment_df_combined_predictions[0].flatten(), name='Sentiment Predictions')\n",
        "sarcasm_predictions = pd.Series(sentiment_df_combined_predictions[1].flatten(), name='Sarcasm Predictions').apply(lambda x: 1 if x > 0.5 else 0)\n",
        "\n",
        "sentiment_predictions"
      ],
      "metadata": {
        "id": "Bbpyf2wCEPBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_scores = convert_to_discrete(sentiment_test_labels['sentiment_output'])\n",
        "calculated_scores = convert_to_discrete(sentiment_df_combined_predictions[0])\n",
        "print(original_scores)\n",
        "print(calculated_scores)\n",
        "calculate_metrics(np.array(original_scores), np.array(calculated_scores))"
      ],
      "metadata": {
        "id": "okST2KNvEK3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-Tune on Yelp Data (train with categorical crossentropy as loss funciton)\n",
        "history = combined_model.fit(X_train_yelp, yelp_train_labels,\n",
        "                             validation_data=(X_val_yelp, yelp_val_labels),\n",
        "                             epochs=10,\n",
        "                             batch_size=2048)"
      ],
      "metadata": {
        "id": "hov3lRHQELMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_continuous_test = combined_model.predict(X_test_yelp)\n",
        "predicted_rounded_test = convert_to_discrete(predicted_continuous_test[0])\n",
        "yelp_df_test[\"Combined Model Score\"] = predicted_rounded_test"
      ],
      "metadata": {
        "id": "InFviJWp0YSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5ab6d95-fe31-4613-bffd-50178cdcb468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "931/931 [==============================] - 69s 74ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_scores = yelp_df_test['Score'].values\n",
        "calculated_scores = convert_to_discrete(yelp_df_test[\"Combined Model Score\"].values)\n",
        "calculate_metrics(original_scores, calculated_scores)"
      ],
      "metadata": {
        "id": "RwLkFYmEEWO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(combined_model, X_val_yelp, y_val_yelp, val_sarcasm_labels_binary, X_test_yelp, y_test_yelp, test_sarcasm_labels_binary)"
      ],
      "metadata": {
        "id": "6qE_WMU7EYPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Multi-Head Attention Combined Model"
      ],
      "metadata": {
        "id": "_UXUVXjmzaKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_weights = '/content/drive/MyDrive/Yelp Dataset/model_sentiment_weights.h5'\n",
        "sarcasm_weights = '/content/drive/MyDrive/Yelp Dataset/model_sarcasm_weights.h5'\n",
        "# sentiment_weights = '/content/drive/MyDrive/WPI/DS595_NLP/Final Project/model_sentiment_yelp_weights.h5'\n",
        "# sarcasm_weights = '/content/drive/MyDrive/WPI/DS595_NLP/Final Project/model_sarcasm_weights.h5'\n",
        "\n",
        "model_dim = 64\n",
        "num_heads = 4\n",
        "input_shape = 100  # max_length for sentiment and sarcasm models\n",
        "reg_factor = 0.01\n",
        "\n",
        "# Rebuild the sentiment model architecture\n",
        "sentiment_base = tf.keras.Sequential([\n",
        "    Embedding(10000, 100, input_length=input_shape),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(32)),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(reg_factor)),\n",
        "    BatchNormalization()\n",
        "])\n",
        "\n",
        "sentiment_base.load_weights(sentiment_weights, by_name=True)\n",
        "for layer in sentiment_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Rebuild the sarcasm model architecture\n",
        "sarcasm_base = tf.keras.Sequential([\n",
        "    Embedding(10000, 100, input_length=input_shape),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dropout(0.5),\n",
        "    Dense(24, activation='relu', kernel_regularizer=l2(reg_factor)),\n",
        "    BatchNormalization()\n",
        "])\n",
        "\n",
        "sarcasm_base.load_weights(sarcasm_weights, by_name=True)\n",
        "for layer in sarcasm_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Shared input layer for both tasks\n",
        "input_layer = Input(shape=(input_shape,))\n",
        "\n",
        "sentiment_features = sentiment_base(input_layer)\n",
        "sarcasm_features = sarcasm_base(input_layer)\n",
        "\n",
        "# Combine the outputs from both models\n",
        "combined_features = Concatenate()([sentiment_features, sarcasm_features])\n",
        "\n",
        "# Multi-Head Attention blocks\n",
        "transformed_features = Dense(model_dim, activation='relu')(combined_features)\n",
        "transformed_features = BatchNormalization()(transformed_features)\n",
        "normalized_features = LayerNormalization(epsilon=1e-6)(transformed_features)\n",
        "attn_output = MultiHeadAttention(num_heads=num_heads, model_dim=model_dim)(normalized_features)\n",
        "\n",
        "transformed_features_2 = Dense(model_dim, activation='relu')(attn_output)\n",
        "transformed_features_2 = BatchNormalization()(transformed_features_2)\n",
        "normalized_features_2 = LayerNormalization(epsilon=1e-6)(transformed_features_2)\n",
        "attn_output_2 = MultiHeadAttention(num_heads=num_heads, model_dim=model_dim)(normalized_features_2)\n",
        "\n",
        "pooled_output = GlobalAveragePooling1D()(attn_output_2)\n",
        "\n",
        "combined_dense = Dense(32, activation='relu', kernel_regularizer=l2(reg_factor))(pooled_output)\n",
        "combined_dense = BatchNormalization()(combined_dense)\n",
        "combined_dense = Dropout(0.5)(combined_dense)\n",
        "\n",
        "sentiment_output = Dense(1, activation='sigmoid', name='sentiment_output')(combined_dense)\n",
        "sarcasm_output = Dense(1, activation='sigmoid', name='sarcasm_output')(combined_dense)\n",
        "\n",
        "combined_model_attn = Model(inputs=input_layer, outputs=[sentiment_output, sarcasm_output])\n",
        "combined_model_attn.compile(optimizer=Adam(0.001),\n",
        "                       loss={'sentiment_output': 'categorical_crossentropy', 'sarcasm_output': 'binary_crossentropy'},\n",
        "                       metrics={'sentiment_output': ['mean_absolute_error'], 'sarcasm_output': ['accuracy']})\n",
        "\n",
        "combined_model_attn.summary()"
      ],
      "metadata": {
        "id": "kqAT5YcX2Bot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f330057-20aa-4f44-b688-dfbfd1e15280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " sequential_4 (Sequential)   (None, 64)                   1130112   ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " sequential_5 (Sequential)   (None, 24)                   1087672   ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 88)                   0         ['sequential_4[0][0]',        \n",
            " )                                                                   'sequential_5[0][0]']        \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 64)                   5696      ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 64)                   256       ['dense_9[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization (Layer  (None, 64)                   128       ['batch_normalization_2[0][0]'\n",
            " Normalization)                                                     ]                             \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, None, 64)             16448     ['layer_normalization[0][0]'] \n",
            " iHeadAttention)                                                                                  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, None, 64)             4160      ['multi_head_attention[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, None, 64)             256       ['dense_10[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, None, 64)             128       ['batch_normalization_3[0][0]'\n",
            " erNormalization)                                                   ]                             \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, None, 64)             16448     ['layer_normalization_1[0][0]'\n",
            " ltiHeadAttention)                                                  ]                             \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 64)                   0         ['multi_head_attention_1[0][0]\n",
            " GlobalAveragePooling1D)                                            ']                            \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 32)                   2080      ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 32)                   128       ['dense_11[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 32)                   0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " sentiment_output (Dense)    (None, 1)                    33        ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " sarcasm_output (Dense)      (None, 1)                    33        ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2263578 (8.63 MB)\n",
            "Trainable params: 45474 (177.63 KB)\n",
            "Non-trainable params: 2218104 (8.46 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = combined_model_attn.fit(X_train_yelp, yelp_train_labels,\n",
        "                                       validation_data=(X_val_yelp, yelp_val_labels),\n",
        "                                       epochs=10,\n",
        "                                       batch_size=512,\n",
        "                                       callbacks=[reduce_lr, early_stopping])"
      ],
      "metadata": {
        "id": "KCesp9t2EdkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_continuous_test = combined_model_attn.predict(X_test_yelp)\n",
        "predicted_rounded_test = convert_to_discrete(predicted_continuous_test[0])\n",
        "yelp_df_test[\"Combined Attention Model Score\"] = predicted_rounded_test"
      ],
      "metadata": {
        "id": "BRJRBzfeEge9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_scores = yelp_df_test['Score'].values\n",
        "calculated_scores = convert_to_discrete(yelp_df_test[\"Combined Attention Model Score\"].values)\n",
        "calculate_metrics(original_scores, calculated_scores)"
      ],
      "metadata": {
        "id": "NYPygqaVEgZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(combined_model_attn, X_val_yelp, y_val_yelp, val_sarcasm_labels_binary, X_test_yelp, y_test_yelp, test_sarcasm_labels_binary)"
      ],
      "metadata": {
        "id": "wSnFB0d5EgSd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}